x-airflow-env: &airflow_env
  AIRFLOW__CORE__EXECUTOR: LocalExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow_db:5432/airflow
  AIRFLOW__CORE__LOAD_EXAMPLES: "false"

  AIRFLOW__CORE__AUTH_MANAGER: airflow.api_fastapi.auth.managers.simple.simple_auth_manager.SimpleAuthManager
  AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_USERS: "admin:admin,viewer:viewer"
  AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_ALL_ADMINS: "true"

  AIRFLOW__CORE__EXECUTION_API_SERVER_URL: "http://airflow-api-server:8080/execution"

  AIRFLOW__API_AUTH__JWT_SECRET: "QSqUagxVzwwduL9ML5VDysN81O8T8qta3_x2R9tEBBoe6lCWq5MphopUS8TIyerV"

  PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-docker"

  AIRFLOW__CORE__PARALLELISM: "4"
  AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: "2"
  AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY: "8"

services:
  traefik:
    image: traefik:v3.6.7
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
    ports:
      - "80:80"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "postgres"

  db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_DB: montra_db
      POSTGRES_USER: montra_user
      POSTGRES_PASSWORD: montra_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "postgres"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.2.4
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - ES_JAVA_OPTS=-Xms768m -Xmx768m
    ports:
      - "9200:9200"
    networks:
      - montra_net
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 30

  logstash:
    image: docker.elastic.co/logstash/logstash:9.2.4
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "12201:12201/udp"   # GELF input
    networks:
      - montra_net
    volumes:
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - LS_JAVA_OPTS=-Xms256m -Xmx256m

  kibana:
    image: docker.elastic.co/kibana/kibana:9.2.4
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - montra_net
  
  migrate:
    build: .
    depends_on:
      - db
    environment:
      POSTGRES_DB: montra_db
      POSTGRES_USER: montra_user
      POSTGRES_PASSWORD: montra_pass
      POSTGRES_HOST: db
      POSTGRES_PORT: "5432"
      DJANGO_SECRET_KEY: "django-insecure-=jqx=1*u8ws909jm-dtp4wlw^8@5pcv$2)no-71%pb3=b83_!u"
      DJANGO_DEBUG: "1"
    command: >
      sh -c "
      python manage.py migrate &&
      python manage.py collectstatic --noinput &&
      python manage.py seed_categories
      "
    networks:
      - montra_net
    restart: "no"

  seed_faker:
    build: .
    depends_on:
      - db
      - migrate
    environment:
      POSTGRES_DB: montra_db
      POSTGRES_USER: montra_user
      POSTGRES_PASSWORD: montra_pass
      POSTGRES_HOST: db
      POSTGRES_PORT: "5432"
      DJANGO_SECRET_KEY: "django-insecure-=jqx=1*u8ws909jm-dtp4wlw^8@5pcv$2)no-71%pb3=b83_!u"
      DJANGO_DEBUG: "1"
    command: >
      sh -c "
      python manage.py generate_faker_data 20 50 200 &&
      python manage.py load_faker_data
      "
    networks:
      - montra_net
    restart: "no"

  web:
    build: .
    depends_on:
      - db
      - migrate
    environment:
      POSTGRES_DB: montra_db
      POSTGRES_USER: montra_user
      POSTGRES_PASSWORD: montra_pass
      POSTGRES_HOST: db
      POSTGRES_PORT: "5432"
      DJANGO_SECRET_KEY: "django-insecure-=jqx=1*u8ws909jm-dtp4wlw^8@5pcv$2)no-71%pb3=b83_!u"
      DJANGO_DEBUG: "1"
      ALLOWED_HOSTS: "localhost,127.0.0.1"
      REDIS_URL: "redis://redis:6379/1"
      EXCHANGERATE_API_KEY: "${EXCHANGERATE_API_KEY:-}"
      EXCHANGE_RATE_TTL: "3600"
    command: >
      sh -c "
      gunicorn montra.wsgi:application
      --bind 0.0.0.0:8000
      --workers 2
      --access-logfile -
      --error-logfile -
      "
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.montra.rule=Host(`localhost`)"
      - "traefik.http.routers.montra.entrypoints=web"
      - "traefik.http.services.montra.loadbalancer.server.port=8000"
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "web"
    networks:
      - montra_net

  spark_job:
    build:
      context: .
      dockerfile: spark/Dockerfile
    depends_on:
      - db
    environment:
      POSTGRES_DB: montra_db
      POSTGRES_USER: montra_user
      POSTGRES_PASSWORD: montra_pass
      POSTGRES_HOST: db
      POSTGRES_PORT: "5432"
    command: >
      /opt/spark/bin/spark-submit
      /opt/app/spark_jobs/monthly_category_report.py
    networks:
      - montra_net
    restart: "no"
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "spark_job"

  redis:
    image: redis:7-alpine
    restart: always
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "redis"

  airflow_db:
    image: postgres:15
    container_name: airflow_db
    restart: unless-stopped
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    networks:
      - montra_net

  airflow-init:
    image: apache/airflow:3.1.6
    container_name: airflow-init
    depends_on:
      - airflow_db
    restart: "no"
    environment: *airflow_env
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: ["airflow", "db", "migrate"]
    networks:
      - montra_net

  airflow-api-server:
    image: apache/airflow:3.1.6
    container_name: airflow-api-server
    depends_on:
      - airflow-init
    restart: unless-stopped
    environment: *airflow_env
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8081:8080"
    command: ["airflow", "api-server", "--apps", "all"]
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "airflow_api_server"

  airflow-scheduler:
    image: apache/airflow:3.1.6
    container_name: airflow-scheduler
    depends_on:
      - airflow-init
      - airflow-api-server
    restart: unless-stopped
    environment: *airflow_env
    user: "0:0" # da, znam, opaki security risk u produkciji, ali je okej za dev
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    command: ["airflow", "scheduler"]
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "airflow_scheduler"

  airflow-dag-processor:
    image: apache/airflow:3.1.6
    container_name: airflow-dag-processor
    depends_on:
      - airflow-init
      - airflow-api-server
    restart: unless-stopped
    environment: *airflow_env
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: ["airflow", "dag-processor"]
    networks:
      - montra_net
    logging:
      driver: gelf
      options:
        gelf-address: "udp://127.0.0.1:12201"
        tag: "airflow_dag_processor"


volumes:
  postgres_data:
  es_data:
  airflow_postgres_data:

networks:
  montra_net:
    name: montra_net
    driver: bridge